---
title: 文件上传流程总结
date: 2024-10-02
tags: 任务调度 延时任务
categories: 系统设计
author: xyhao
keywords: 之所以要用延时任务就是为了将更新数据库的时间延时到下一个文件片更新之后，然后将延时的时间继续向后延，避免反复请求数据库。个人理解这是一种动态延时任务。
description: 开始背JUC八股的起点111
top_img: https://raw.githubusercontent.com/Juzi-xyhao/Juzi-xyhao.github.io/master/assets/articleCover/2024-10-02-fileUpLoad.png
cover: https://raw.githubusercontent.com/Juzi-xyhao/Juzi-xyhao.github.io/master/assets/articleCover/2024-10-02-fileUpLoad.png
comments: true
---

> 更多博客请见 [我的语雀知识库](https://www.yuque.com/u41117719/xd1qgc)  
> 之所以延时任务就是为了将更新数据库的时间延时到下一个文件片更新之后，然后延时任务刷新，避免反复请求数据库。  
> 个人理解这是一种动态延时任务。

<h2 id="HNCfK">1. 背景</h2>
文件上传是一个很古老的业务了，业界在设计的时候都会规划三个功能：秒传、分片上传、断点续传。

<h3 id="IOg4G">1.1 MD5密码杂凑算法</h3>
在介绍这三点之前，需要先了解MD5算法。这是一种密码杂凑算法，对于给定的任何输入，都会输出128位固定长度的16进制数字。既然长度固定，就会有重复的风险。国产算法SM3就是MD5的改良版，它优化了加密流程，也将输出的比特数增加到256位。

MD5重复的问题不是本文的重点，因此在接下来的叙述中不会考虑MD5重复的问题。

针对于MD5算法，我们任意输入文件名不同但文件内容相同的文件，都能得到相同的MD5值。这就是秒传的原理。如果数据库中已经存在客户端传过来的MD5值，那就说明以前有人已经上传过这份文件了，只需要新增一条用户和文件的对应关系即可。可以通俗的理解为：MD5值就是文件的身份证。

<h3 id="qG3Fb">1.2 表结构设计</h3>
很明显，用户和文件之间是多对多的关系。

我思考过两种表结构：

1. 只建立用户表和文件表，在文件表里关联用户表主键。
2. 建立用户表、文件表、用户文件关联表。

考虑到网盘的场景，文件内容相同的文件虽然文件名不同，但它们实际上还是同一份文件。

<h4 id="chUQJ">1.2.1 采用第一种方案</h4>
<h5 id="mGYkV">1.2.1.1缺点：</h5>
MD5不能做主键，放着天然的主键属性不要，得让业务去生成主键。假如说有一个文件`程序员的自我修养.txt`，A用户上传完成后，在文件表增加一条`程序员的自我修养.txt->A`的一行数据。B把它更名为`自我修养.txt`上传，虽然文件名不同，MD5值却是相同的。但是文件表里肯定要再插入一条数据`自我修养.txt->B`的记录。MD5做主键就会冲突。但是这不是什么要紧的事。

<h5 id="W5ezw">1.2.1.2 优点：</h5>
相比于第二种方案，可以少建一张表，且避免了回表查询。

<h4 id="N6wWV">1.2.2采用第二种方案</h4>
<h5 id="Vaj5z">1.2.2.1缺点：</h5>
1. **MD5还是不能做主键**。在这种方案里，如果文件表用MD5做主键，同一份文件只有一行数据，A对这个文件的文件名做了修改，在B用户看来，文件名是被同步修改的。B用户肯定就会觉得碰上鬼打墙了，他啥都没干文件名就被改了。
2. **要多建一张表，且会导致回表查询。**查询某个用户上传的全部文件。如果是建立关联表的话，得先查关联表，拿到文件ID列表再去做回表查询。但如果是在文件表加用户字段，只需要查询 `where userID ＝ xxx`就可以把用户上传的全部文件查出来。

<h5 id="oUDll">1.2.2.2优点：</h5>
相比于第一种方案并没有什么优点。

<h3 id="pruJk">1.3 三个功能</h3>
+ **秒传：**发现数据库里已经存在相同MD5值的文件时，去文件表新增一行数据，判定此次上传完毕。
+ **分片上传：**将文件划分为多个子部分，分别上传每个子部分，是断点续传的实现原理。
+ **断点续传：**如果上一次上传被中断需要重新上传，不需要从头开始上传，而是从上一次已上传的最新部分开始上传。接下来深度分析的业务问题都是关于断点续传的。

<h3 id="P5XN7">1.4 总结</h3>
虽然由于场景限制导致MD5这一天然的主键属性不能作为主键，这是产品特性决定的，同一份文件可能在不同用户的视角下名字不一样。但是MD5这个属性可以建立非唯一索引。

总体来看，流程比较简单，但是深究起来其中还是有不少可以挖掘的业务问题。

<h2 id="BPwjb">2. 没上传完怎么办？</h2>
<h3 id="kO2gu">2.1 上传后的文件片怎么处理？</h3>
服务端需要将上传的那些文件片按照一定的规则（年-月）保存在临时目录中。出于需要实现断点续传的考虑，临时目录不能立马删掉。得保存一段时间。

+ 把删除临时目录的任务发送到MQ？没有必要。在MQ不出现消息积压的情况下，几秒钟内消息就会被消费。破坏了断点续传。

我认为最好的办法就是在月初统一删除上一个月的临时目录。比如第一级文件夹是xxxx年，第二级是xx月，里面保存了所有在xx月上传的文件片(当然根据需要也可以精确到天，增加三级目录xx天)。虽然会导致极端场景下断点续传失效（月底的晚上开始上传），但没必要为了极端场景做非常多优化。这些优化本身的成本可能比极端场景发生后的损失还大。技术总是服务于业务、服务于公司的。（那我现在写的就是极端场景下恶意上传打垮服务器的解决方案，为什么要考虑它的解决方案？不考虑解决方案我怎么写简历？）

<h3 id="htm8V">2.2 有人恶意攻击怎么办</h3>
前面说到文件片按照一定的规则（年-月）保存在临时目录中，月初才清理。

且文件片只有在全部上传完毕后才会合并，并更新用户已使用空间。

**假如现在硬盘资源有限，有人从月初开始攻击服务器，具体表现为上传文件时不上传完。那么这些上传的文件碎片就会白白占据服务器硬盘资源而上传它们的用户的已使用空间却不会增加。久而久之用户上传的文件片已经远远超过他们的额度，服务器硬盘资源会被打垮**。怎么解决？

<h3 id="H4MY4">2.3 解决方案</h3>
每个文件片上传时都去数据库里增加用户已使用空间吗？这会不会给数据库带来压力呢？数据库是整个服务端的最后方的组件，将数据持久化至硬盘，因此数据库本身的QPS完全比不上缓存。所以不能随随便便就请求数据库。

那就引入缓存？

将用户的已使用空间保存在redis里面？那是不是要考虑和数据库的一致性呢？如果需要保证和数据库的一致性，那和直接更新数据库没有任何区别，因为这些请求全部是写请求。

如果不保证和数据库的一致性呢？用户上传到一半手动取消上传了，从用户角度考虑，用户肯定不希望在查看已使用空间时看到取消上传的文件还占据着已使用空间。这就带来一个新的问题：**服务器视角下的已使用大小是已上传完毕的文件总大小加上未上传完毕的总大小。用户视角下的已使用大小是他已经上传完毕的那些文件的总大小（**实际使用中发现百度网盘、夸克网盘等等都是这样做的）。这就需要我们准备两套计算已使用大小的方案。

在用户表里用两个字段分别表示已上传完毕的文件总大小以及未上传完毕的总大小。前者只在文件片合并和删除文件时更新即可，**后者则是每有一个文件片上传都需要更新**。

服务器在判断是否超出限额时需要将两者相加。

但是这样做和直接更新数据库还是没有区别。有多少文件片被上传就要更新多少次数据库。能不能减少更新次数？

注意到即使更新无数次数据库，每一次更新都可以覆盖前一次更新。

<h4 id="z58sA">2.3.1 举个例子</h4>
第一次更新是将未上传完大小`100M`加上这次文件片的大小`5M`得到`105M`；第二次更新是将未上传完大小`105M`加上这次文件片的大小`5M`得到`110M`。更新了两次数据库。如果在第二次更新时加上`5M * 2 = 10M`，再把第一次更新删除，也就是`100M + 10M = 110M`。这样做只更新了一次数据库。



**因此考虑引入延时任务,每个文件片上传后，在上一个延时任务执行之前刷新延时任务，将它接着向后延。让最后一次更新覆盖之前所有更新，做到只更新一次数据库。**

<h3 id="i6IQP">2.4 延时任务</h3>
<h4 id="d614D">2.4.1 存储延时任务的结构</h4>
<h5 id="STJl2">列表</h5>
<font>插入：O(1)</font>

<font  >查询：O(logN)</font>

<font  >实现：我们可以利用列表去存即将触发的任务信息，通过遍历的方式去取到大于当前时间的任务，并且触发。</font>

<font  >优点：实现简单</font>

<font  >缺点：但需要对所有任务进行遍历，查出很多无效数据，极其低效。</font>

<h5 id="82197238">大顶堆</h5>
<font  >删除：O(logN)</font>

<font  >查询：O(1)</font>

<font  >实现：我们也可以利用大顶堆的性质，每次都取堆顶元素，如果堆顶元素大于当前时间，那么就取最大元素。其余元素会利用大顶堆的性质，继续浮出最大的元素，然后继续比较。</font>

<font  >优点：查询快，只会查到快到时间的任务，实现简单。</font>

<font  >缺点：需要维护自身堆的性质，cpu压力高，无法抗住高并发。</font>

<h5 id="19dd3d1e">B+树</h5>
<font  >查询：O(logN)</font>

<font  >B+树（B-plus tree）是一种自平衡的树数据结构，它能够保持数据有序，允许插入、删除和查找操作在对数时间内完成。
B+树特别适合于磁盘或其他直接存取辅助设备的存储系统，因为它能够最大化地减少I/O操作次数。</font>

<h5 id="b9130034">跳表</h5>
<font  >查询：O(logN)</font>

<font  >跳表（Skip List）是一种基于有序链表的高效数据结构，它通过在链表的基础上增加多级索引来实现快速的查找操作。
跳表允许在对数时间内完成搜索、插入和删除操作，且插入和删除操作不需要频繁调整数据结构。</font>

<h5 id="cc1d28d4">小总结</h5>
<font  >总的来说，列表和大顶堆由于自身的性质，并不适合这样的场景。对于扫表+触发的模式，其实本质是需要一个能高速范围查询的数据结构。</font>

<font  >B+树和跳表都是高效的能范围查询数据结构，但它们各自适用于不同的场景。B+树更适合于</font>**<font  >磁盘存储和范围查询</font>**<font  >，而跳表则更适合于</font>**<font  >内存中的快速查找和分布式环境</font>**<font  >。</font>

<h4 id="3c460321">2.4.2 存储数据库分析</h4>
<font  >我们举出基于内存的数据库的代表Redis和基于磁盘的数据库进行分析。</font>

<h5 id="redis-vs-mysql">Redis VS MySQL</h5>
<font  >1.Redis的底层是跳表，而MySQL的底层是B+树。就范围查询而言，两者</font>**不分伯仲** 

<font  >2.但Redis没有事务概念，内部实现是单线程，没有锁竞争，再加上IO多路复用的特性和极其高效的数据结构实现，就注定单机qps要远超过mysql</font>

<font  >3.mysql在这个场景下的优势则是有持久化能力，不容易丢数据，Redis可能在RDB和AOF的过程中有</font>**丢数据**的可能性

<font  >因此，mysql和redis都有可能是作为存储任务的数据库，需要区分场景。</font>

综合考虑下我选用Redis。虽然Redis有丢数据的风险无法完美保证延时任务不丢，但是在本文中描述的延时任务是不断更新的，是动态的。比如某条数据现在是10M，然后执行RDB备份。再然后更新延时任务变成11M，假设此时宕机，11M这个数据没保存下来，但是10M这个数据已经保存了啊。虽然丢了一点数据。
但是不多。系统停机维护时把延时任务和临时目录全删了，再把数据库中记录用户未上传完大小的这个字段置为0。一切又回到最初的起点。

如果用mysql存储动态延时任务，那就要经常更新mysql。其实也可以。但是mysql扛不住比较大的QPS，速度不如redis。综合考虑我还是用redis存延时任务。

<h4 id="Whhk8">2.4.3缓存一致性问题</h4>
只要涉及到了缓存和数据库就一定会有缓存一致性问题，延时任务也不例外。

redis先更新，数据库的更新取决于延时任务被执行的时间，如果redis宕机导致某一条延时任务丢了，数据库就永远不会更新。当然即使数据库没有被更新对业务也产生不了什么影响。因为这条数据在redis里有缓存。读数据也是读redis。因此**是否出现缓存不一致只取决于redis宕机后是否丢失相关数据和延时任务是否成功执行**。

这和平常说的缓存一致性问题是不一样的。平常说的缓存一致性指的是先操作数据库还是缓存，更新缓存还是删除缓存。一致性带来的问题是**脏读和更新数据库失败导致缓存数据无效**。

但是在现在描述的这个场景里不会有脏读的发生。**更新数据库失败导致缓存失效倒是有可能发生。这个问题的解决思路就可以参考八股文了。比如通过消息队列的重试机制。**

<h4 id="DbWTf">2.4.4 延时任务的具体思路</h4>
文件片被上传时，用一个redis的String类型保存该用户未上传完毕的文件大小，叫它`unfinishedFileSize`。再用一个`finishedFileSize`记录已上传完毕的文件大小。`unfinishedFileSize`需要通过延时任务保证和数据库的一致性。`finishedFileSize`是用户视角下的已使用空间，`unfinishedFileSize + finishedFileSize`是服务器视角下的已使用空间大小。


```java
class Member{
    /*
        已重置为0的总大小，当一个延时任务被执行后，
        finishedDBSize += unfinishedDBSize;
        unfinishedDBSize = 0;
        
        该文件完全上传完毕后，将(finishedDBSize + unfinishedDBSize)从表中该用户的未上传完毕大小中减去
        因为finishedDBSize代表已经更新至数据库的未上传完毕大小，unfinishedDBSize代表还没有更新到数据库的未上传完毕大小
        但是unfinishedDBSize一定会被延时任务给执行，所以先删和后删没区别
    */
    long unfinishedSize;// 已更新至数据库的未上传完成大小
    long unfinishedDBSize;// 待更新至数据库的未上传完成大小
    String userID;//当zset里的时间戳重复时，就要根据member里记录的用户id信息锁定唯一一条entry
    String md5;//标识唯一文件
    int flag;//标识当前延时任务是否被执行
}
```


定义zset中的member

![](https://raw.githubusercontent.com/Juzi-xyhao/Juzi-xyhao.github.io/master/assets/articleSource/2024-10-02-fileIUpLoad/img.png)

redis的整体结构设计


```sql
create table user_info
(
    user_id         varchar(12)      not null primary key,
    use_space_finished bigint default 1024 comment '已上传完毕文件使用总空间,单位byte',
    use_space_unfinished bigint default 0 comment '未上传完毕文件使用总空间,单位byte',
    total_space     bigint           comment '总空间'
)
    
```


用户表相关字段

某文件第一个文件分片上传完后，先更新`unfinishedFileSize`。然后将当前时间戳作为分数，该文件已上传的文件片大小总和等信息作为`member`加入到`zset`中。同时使用一个`map`记录`文件md5值+用户id`和`时间戳`的对应关系。

> 为什么map不是维护文件id作为key呢？
>
> 主要是考虑到在文件被完全上传完之前，确定id没有意义。除非客户端在上传一个文件时携带id，且保证发生断点续传时，第二次上传携带的id和第一次相同。但是满足这个条件的id的生成规则肯定和雪花算法不同，因为雪花算法生成的id和时间有关，但当前场景下需要时间无关。注意。这里的意思并不是说一个文件被重复上传时客户端生成的id前后都一样，而是在一次上传流程中，如果因为应用重启等原因出现了中断，中断后的上传请求中的文件id和中断前保持相同。重复上传时的id则必须不同。
>
> 而且这篇文章是针对于服务端的，我假设客户端上传时不携带id信息。另外，我认为**服务端一个重要的原则就是不要相信客户端传来的数据**，能做检验的数据一定要做检验。客户端传来的数据都是可以被篡改的。https虽然安全，但如果出现了中间服务器，https报文就变成明文了。
>
除第一个文件片之外的其它文件片上传时，根据`map`通过`用户id + 文件md5值`获取zset里的`score`，更新它(更新时间戳)。
不断使用`ZRANGEBYSCORE`命令扫描其中的延时任务，将扫描到的任务里的member里的`unfinishedDBSize` 更新到数据库保证一致性。

当所有文件片正常上传完触发文件片合并，然后数据库更新`use_space_finished`字段。

之后根据`map`通过`用户id + 文件md5值`获取`score`，再根据这个`score`获取`zset`中该文件的`unfinishedDBSize`和`unfinishedSize`。

执行`use_space_unfinished` = `use_space_unfinished` - `unfinishedDBSize` - `unfinishedSize`。**这是补偿用户的操作**。

因为延时任务肯定会被执行的(`use_space_unfinished` = `use_space_unfinished` + `unfinishedDBSize`)，先减`unfinishedDBSize`和后减`unfinishedDBSize`没区别。至于`unfinishedSize`？只要这个文件的延时任务没有被执行过，它就是0。即使执行过也没关系，见[3.4 考虑断点续传，用户只上传了一部分就宕机了，然后恢复机器继续上传。但是此时这个文件在zset里的任务已经更新到数据库了。后续的一部分文件上传是什么流程？](#EG571)

（**延时任务能不能成功执行至关重要！！！最终一致性全靠它保证！！！**）

<h4 id="av8rA">2.4.5 总结</h4>
所以一个文件片上传完后，有六个步骤：

1. 根据`文件md5值+用户id`去`map`里找到上一个文件片延时任务的时间戳
2. 去`zset`里删除该`时间戳`
3. 向`zset`里添加本次文件片的时间戳作为`score`,该文件已上传部分的大小和已重置为0的总大小等信息作为`member`。
4. 写`map`，更新`文件md5值+用户id`对应的延时任务时间戳。
5. 执行延时任务，`use_space_unfinished` = `use_space_unfinished` + `unfinishedDBSize`
6. 文件上传完成，`use_space_unfinished` = `use_space_unfinished` - `unfinishedDBSize` - `unfinishedSize`

**第五步和第六步的执行顺序没有要求！谁先执行都可以。**

<h3 id="Ixq6i">2.5 延时任务执行调度</h3>
当任务量很大时，任务的执行调度也需要花心思设计。具体参考[高性能调度系统设计总结](https://juzi-xyhao.github.io/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/2024/08/30/%E9%AB%98%E6%80%A7%E8%83%BD%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E6%80%BB%E7%BB%93.html)



<h2 id="RsYpu">3. A&Q</h2>
<h3 id="rYkkf">3.1 延时任务重复问题</h3>
一个文件多个分片上传，会造成该文件有多个延时任务。也就说一个分片一个延时任务。如何解决重复的问题？

记录延时任务的同时，把上一个分片加的任务删了。

怎么删？根据`文件md5值+用户id`去`map`里获取上一个任务的时间戳。再去`zset`里删除这个时间戳

<h3 id="Xmomy">3.2 用户开多个客户端同时上传，怎么保证延时任务更新正确？</h3>
`zset`中的延时任务只和某一个文件有关。开多个客户端上传多个文件，就会出现多个延时任务，彼此互不干扰，并不会有什么问题。

<h3 id="Y0hw1">3.3 用户开多个客户端同时上传，怎么保证不会超过限额？</h3>
有`finishedFileSize`和`unfinishedFileSize`两个字符串类型分别记录每个用户已上传完毕大小和未上传完毕大小。

去`redis`里增加一个`String`字段，用于记录该用户正在上传的所有文件的总大小，叫它`upLoadingFileSize`。  

每个文件上传时，前端把文件总大小也传过来。更新`upLoadingFileSize`。

通过`unfinishedFileSize`+ `finishedFileSize`+ `upLoadingFileSize` > `total_Space`的结果就可以知道这个文件能不能上传了。

显示给用户看的已使用空间就是`finishedFileSize`。只把`finishedFileSize`返回即可。 

<h3 id="EG571">3.4 考虑断点续传，用户只上传了一部分就宕机了，然后恢复机器继续上传。但是此时这个文件在zset里的任务已经更新到数据库了。后续的一部分文件上传是什么流程？</h3>
**举个场景例子并给出解决方案：**

某用户在数据库中`use_space_unfinished`字段是0。`zset`里`unfinishedDBSize`字段是10M，`finishedDBSize`字段是`0M`。然后用户宕机，导致延时任务没有被刷新而是被触发，导致用户在数据库中的`use_space_unfinished`字段数据被更新为`10M`。

此时zset里`unfinishedDBSize`字段是`0M`，`finishedDBSize`字段是`10M`。用户重启客户端发生断点续传，下一个大小为`1M`的文件片被上传了。于是写`zset`将`unfinishedDBSize`字段更新为`1M`，没有对业务产生影响。

假如这个大小为`1M`的文件片是最后一个文件片，上传完服务器就触发了文件片合并流程，并从`zset`中获取到延时任务，将其中`finishedDBSize + unfinishedDBSize = 11M`的值从用户在数据库中的`use_space_unfinished`字段中减去，也就是`use_space_unfinished`  = `use_space_unfinished` - `finishedDBSize + unfinishedDBSize` = 10M -11M = -1M。

别慌，还有延时任务。

延时任务的执行会让`use_space_unfinished` = `use_space_unfinished` + `unfinishedDBSize` =`0`。所以文件被完全上传完后补偿用户的操作和延时任务的执行操作，两者的执行时间没有时间上的先后顺序。**但是延时任务一定要被成功执行，不然最终一致性就不能得到保证。**



<h3 id="bBKci">3.5 如果文件被完全上传后取出延时任务补偿用户时能把延时任务删除，能显著降低延时任务的数量吧？</h3>
我有过这个优化的思路，在延时任务中加入一个变量表示延时任务的执行状态。以上文中提到的场景为例：假如取出延时任务是`命令A`，执行延时任务是`命令B`。在`redis`服务器那边，A执行完紧接着就是B执行，我拿到延时任务后发现它还没被执行，于是我把它删了（`命令C`，在`命令B`之后执行），用户在数据库中未上传完毕大小字段变成了`10M - 10M = 0M`，不要以为延时任务被删了不会执行，保证了最终一致性。实际上延时任务还是执行了，用户在数据库中未上传完毕大小字段变成了`0M + 1M = 1M`。最终一致性被破坏。

之所以会发生这种情况就是因为`ZREMRANGEBYSOCRE`命令在删除某个entry时不会把entry返回，得先根据`ZRANGEBYSOCRE`命令获取到延时任务，再通过`ZREMRANGEBYSOCRE`删除延时任务。也就是说：命令A和命令C的组合执行不是原子操作。

为了实现这一点，可以考虑使用`lua脚本`来保证原子性。



<h3 id="UiUQV">能否基于Kafka实现延时队列进而实现本文中的延时任务？</h3>
本文中的延时任务和其它延时任务不太一样，本文中的延时任务需要更新被延时的时间，是动态延时。

如果一个延时任务被发送到Kafka，那我就不能修改它了，不符合本文延时任务的场景。

如何用Kafka实现延时队列？ 参考： [如何用Kafka实现延时队列](https://zhuanlan.zhihu.com/p/365802989#:~:text=%E5%9F%BA%E4%BA%8Ekafka%E5%A6%82%E4%BD%95%E5%AE%9E)
